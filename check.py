# -*- coding: utf-8 -*-
"""Get Target.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12e8KIMG63UBiwPCBLzszJa-SjktwHdEq

##importing libraries
"""

import pandas as pd
import numpy as np
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

"""##importing datasets"""

from google.colab import files
uploaded = files.upload()
dataset = pd.read_csv(list(uploaded.keys())[0])
X = dataset.iloc[:,:-1].values
y = dataset.iloc[:,-1].values
reg = {}
clas = {}
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
sc_y = StandardScaler()
sc = StandardScaler()

"""Multiple Linear Regression"""

def MultipleLinearRegression(X, y):
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
  #model training
  from sklearn.linear_model import LinearRegression
  regressor = LinearRegression()
  regressor.fit(X_train, y_train)
  y_pred = regressor.predict(X_test)
  #evaluation
  evaluation = r2_score(y_test, y_pred)
  reg['Multiple Linear Regression'] = evaluation

"""Polynomial Regression"""

def PolynomialRegression(X, y):
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
  #model training
  from sklearn.preprocessing import PolynomialFeatures
  from sklearn.linear_model import LinearRegression
  poly_reg = PolynomialFeatures(degree = 4)
  X_poly = poly_reg.fit_transform(X_train)
  regressor = LinearRegression()
  regressor.fit(X_poly, y_train)
  y_pred = regressor.predict(poly_reg.transform(X_test))
  #evaluation
  evaluation = r2_score(y_test, y_pred)
  reg['Polynomial Regression'] = evaluation

"""Support Vector Regression"""

def SupportVectorRegression(X, y):
  #splitting the data
  y = y.reshape(len(y),1)
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
  #feature scaling
  X_train = sc_X.fit_transform(X_train)
  y_train = sc_y.fit_transform(y_train)
  #model training
  from sklearn.svm import SVR
  regressor = SVR(kernel = 'rbf')
  regressor.fit(X_train, y_train)
  y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X_test)).reshape(-1,1))
  evaluation = r2_score(y_test, y_pred)
  reg['Support Vector Regression'] = evaluation

"""Decision Tree Regressoion"""

def DecisionTreeRegression(X, y):
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
  #model training
  from sklearn.tree import DecisionTreeRegressor
  regressor = DecisionTreeRegressor(random_state = 0)
  regressor.fit(X_train, y_train)
  y_pred = regressor.predict(X_test)
  #evaluation
  evaluation = r2_score(y_test, y_pred)
  reg['Decision Tree Regression'] = evaluation

"""Random Forest Regression"""

def RandomForestRegression(X, y):
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
  #model training
  from sklearn.ensemble import RandomForestRegressor
  regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)
  regressor.fit(X_train, y_train)
  y_pred = regressor.predict(X_test)
  #evaluation
  evaluation = r2_score(y_test, y_pred)
  reg['Random Forest Regression'] = evaluation

"""##Regression Function Call"""

def regressioncall(X, y):
    MultipleLinearRegression(X, y)
    PolynomialRegression(X, y)
    SupportVectorRegression(X, y)
    DecisionTreeRegression(X, y)
    RandomForestRegression(X, y)
    print(reg)
    print(f"Preferred Regression Model:- {max(reg, key=reg.get)}")

"""Logistic Regression"""

def LogisticRegression(X_train, y_train, X_test, y_test):
  from sklearn.linear_model import LogisticRegression
  classifier = LogisticRegression(random_state = 0)
  classifier.fit(X_train, y_train)
  # (X_train, y_train, X_test):
  y_pred = classifier.predict(X_test)
  evaluation = accuracy_score(y_test, y_pred)
  clas['Logistic Regression'] = evaluation

"""K Nearest Neighbors"""

def KNearestNeighbors(X_train, y_train, X_test, y_test):
  from sklearn.neighbors import KNeighborsClassifier
  classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
  classifier.fit(X_train, y_train)
  y_pred = classifier.predict(X_test)
  evaluation = accuracy_score(y_test, y_pred)
  clas['KNN'] = evaluation

"""Support Vector Machine"""

def SupportVectorMachine(X_train, y_train, X_test, y_test):
  from sklearn.svm import SVC
  classifier = SVC(kernel = 'linear', random_state = 0)
  classifier.fit(X_train, y_train)
  y_pred = classifier.predict(X_test)
  evaluation = accuracy_score(y_test, y_pred)
  clas['SVM'] = evaluation

"""Kernal SVM"""

def KernelSVM(X_train, y_train, X_test, y_test):
  from sklearn.svm import SVC
  classifier = SVC(kernel = 'rbf', random_state = 0)
  classifier.fit(X_train, y_train)
  y_pred = classifier.predict(X_test)
  evaluation = accuracy_score(y_test, y_pred)
  clas['Kernal SVM'] = evaluation

"""Naive Bayes"""

def NaiveBayes(X_train, y_train, X_test, y_test):
  from sklearn.naive_bayes import GaussianNB
  classifier = GaussianNB()
  classifier.fit(X_train, y_train)
  y_pred = classifier.predict(X_test)
  evaluation = accuracy_score(y_test, y_pred)
  clas['Naive Bayes'] = evaluation

""" Decision Tree Classification"""

def DecisionTreeClassification(X_train, y_train, X_test, y_test):
  from sklearn.tree import DecisionTreeClassifier
  classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
  classifier.fit(X_train, y_train)
  y_pred = classifier.predict(X_test)
  evaluation = accuracy_score(y_test, y_pred)
  clas['Decision Tree Classification'] = evaluation

"""Random Forest Classification"""

def RandomForestClassification(X_train, y_train, X_test, y_test):
  from sklearn.ensemble import RandomForestClassifier
  classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
  classifier.fit(X_train, y_train)
  y_pred = classifier.predict(X_test)
  evaluation = accuracy_score(y_test, y_pred)
  clas['Random Tree Classification'] = evaluation

"""##Classification Function Call"""

def classificationcall(X, y):
  # feature scaling
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)
  X_train = sc.fit_transform(X_train)
  X_test = sc.transform(X_test)
  LogisticRegression(X_train, y_train, X_test, y_test)
  KNearestNeighbors(X_train, y_train, X_test, y_test)
  SupportVectorMachine(X_train, y_train, X_test, y_test)
  KernelSVM(X_train, y_train, X_test, y_test)
  NaiveBayes(X_train, y_train, X_test, y_test)
  DecisionTreeClassification(X_train, y_train, X_test, y_test)
  RandomForestClassification(X_train, y_train, X_test, y_test)
  print(clas)
  print(f"Preferred Classification Model:- {max(clas, key=clas.get)}")

"""##Choosing the Model"""

print("Choose your dataset model type")
print("1. Regression")
print("2. Classification")
choice1 = int(input("Enter your choice"))
if choice1 == 1:
  print("Models to be tested are:\n'Multiple Linear Regression'\n'Polynomial Regression'\n'Support Vector Regression'\n'Decision Tree Regression'\n'Random Forest Regression'\n")
  regressioncall(X, y)
elif choice1 == 2:
  print("Models to be tested are:\n'Logistic Regression'\n'K-Nearest Neighbors'\n'Support Vector Machine'\n'Kernel SVM'\n'Naive Bayes'\n'Decision Tree Classification'\n'Random Forest Classification'\n")
  classificationcall(X, y)
else:
  print("Invalid choice")